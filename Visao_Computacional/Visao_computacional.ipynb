{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Carregar a base de dados de treino\n",
        "Você pode usar a biblioteca tensorflow ou keras.preprocessing.image para carregar e pré-processar as imagens, garantindo que elas tenham o formato correto (250x250) antes de realizar a separação dos pacientes."
      ],
      "metadata": {
        "id": "MyvyjfqDvqCD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nuvTn0GSvPlt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Caminho para as imagens de treino\n",
        "train_dir = 'path/to/train/directory'\n",
        "\n",
        "# Função para carregar as imagens e seus rótulos\n",
        "def load_images(train_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label in os.listdir(train_dir):\n",
        "        label_dir = os.path.join(train_dir, label)\n",
        "        for img_file in os.listdir(label_dir):\n",
        "            img = load_img(os.path.join(label_dir, img_file), target_size=(250, 250))\n",
        "            img_array = img_to_array(img)\n",
        "            images.append(img_array)\n",
        "            labels.append(int(label))\n",
        "    return np.array(images), np.array(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Separar por paciente (80% treino e 20% validação)\n",
        "Você pode utilizar a nomenclatura das imagens (XX) para garantir que as partições sejam feitas corretamente por pacientes e evitar o viés."
      ],
      "metadata": {
        "id": "tyXa3DdSvoHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separação por pacientes (XX)\n",
        "def split_by_patient(images, labels):\n",
        "    # Assumindo que XX é a parte inicial do nome da imagem\n",
        "    patients = [img_file.split('_')[0] for img_file in images]\n",
        "    unique_patients = np.unique(patients)\n",
        "    train_patients, val_patients = train_test_split(unique_patients, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_idx = [i for i, patient in enumerate(patients) if patient in train_patients]\n",
        "    val_idx = [i for i, patient in enumerate(patients) if patient in val_patients]\n",
        "\n",
        "    return images[train_idx], labels[train_idx], images[val_idx], labels[val_idx]"
      ],
      "metadata": {
        "id": "XPsI4l9av8T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Extração de características usando LBP e CNN VGG16\n",
        "LBP (Local Binary Patterns) pode ser feito com scikit-image.\n",
        "\n",
        "VGG16: Utilize a VGG16 pré-treinada, remova a última camada e capture os valores da penúltima camada."
      ],
      "metadata": {
        "id": "aS3eEC7PwCqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "# Parâmetros do LBP\n",
        "radius = 1\n",
        "n_points = 8 * radius\n",
        "\n",
        "# Extração de características com LBP\n",
        "def extract_lbp(images):\n",
        "    lbp_features = []\n",
        "    for img in images:\n",
        "        gray_img = rgb2gray(img)  # Converter para escala de cinza\n",
        "        lbp = local_binary_pattern(gray_img, n_points, radius, method='uniform')\n",
        "        lbp_features.append(lbp.flatten())  # Transformar em vetor\n",
        "    return np.array(lbp_features)"
      ],
      "metadata": {
        "id": "MZJK3KJQwJ5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16:"
      ],
      "metadata": {
        "id": "bFRITYpBwMiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Carregar o modelo VGG16 pré-treinado e remover a última camada\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)\n",
        "\n",
        "# Redimensionar as imagens e extrair características\n",
        "def extract_vgg16(images):\n",
        "    resized_images = [resize(img, (224, 224)) for img in images]\n",
        "    features = model.predict(np.array(resized_images))\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "CeMEwpv3wOGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Treinar Random Forest, SVM e RNA\n",
        "Após a extração de características, você pode treinar modelos de aprendizado de máquina, como Random Forest, SVM e RNA."
      ],
      "metadata": {
        "id": "llWr8RA5wSNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Treinamento dos modelos\n",
        "def train_models(train_features, train_labels):\n",
        "    rf = RandomForestClassifier().fit(train_features, train_labels)\n",
        "    svm = SVC().fit(train_features, train_labels)\n",
        "    mlp = MLPClassifier().fit(train_features, train_labels)\n",
        "    return rf, svm, mlp\n"
      ],
      "metadata": {
        "id": "zrZxTNQHwTZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Carregar a base de teste e repetir a extração de características\n",
        "Utilize a mesma abordagem usada no conjunto de treino para extrair as características do conjunto de teste.\n",
        "# 6. Aplicar os modelos treinados nos dados de teste\n",
        "Faça as predições usando os modelos treinados nos dados de teste.\n",
        "\n"
      ],
      "metadata": {
        "id": "I9_C-Q80waRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models(models, test_features, test_labels):\n",
        "    for model in models:\n",
        "        predictions = model.predict(test_features)\n",
        "        # Calcular métricas\n"
      ],
      "metadata": {
        "id": "zD5Q2wY-wgJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Calcular as métricas de Sensibilidade, Especificidade e F1-Score"
      ],
      "metadata": {
        "id": "NK8r2DN6wibF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def calculate_metrics(true_labels, predictions):\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions)\n",
        "    print(report)"
      ],
      "metadata": {
        "id": "L1zKcZCXwkUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.Treinamento com VGG16 e ResNet50 com Data Augmentation\n",
        "Utilize as redes pré-treinadas com keras e ajuste as camadas fully connected para o problema de 4 classes."
      ],
      "metadata": {
        "id": "5Salbvxuwn52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Modelos VGG16 e ResNet50 com Transfer Learning\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(4, activation='softmax')(x)  # 4 classes\n",
        "    return Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)\n"
      ],
      "metadata": {
        "id": "KiSv51dEwr_f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}